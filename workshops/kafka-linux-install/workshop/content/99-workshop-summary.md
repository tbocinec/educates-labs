# Workshop Summary

Congratulations! You've successfully completed the Apache Kafka on Linux workshop.

## What You Learned

### 1. Kafka Installation
- âœ… Downloaded and installed Apache Kafka binaries
- âœ… Set up environment variables
- âœ… Understood Kafka directory structure

### 2. KRaft Mode
- âœ… Learned about KRaft (Kafka without Zookeeper)
- âœ… Generated cluster IDs
- âœ… Formatted storage directories
- âœ… Started Kafka in KRaft mode

### 3. Single Broker Operations
- âœ… Started a single Kafka broker
- âœ… Created topics with partitions
- âœ… Produced messages using console producer
- âœ… Consumed messages using console consumer
- âœ… Worked with consumer groups

### 4. Multi-Broker Cluster
- âœ… Configured a 3-node cluster (1 controller + 2 brokers)
- âœ… Created replicated topics
- âœ… Tested broker failover
- âœ… Verified replica synchronization
- âœ… Monitored cluster health

## Key Concepts Mastered

### KRaft Architecture
- **No Zookeeper dependency** - Simplified deployment
- **Metadata quorum** - Built-in consensus protocol
- **Faster failover** - Improved reliability

### Replication
- **High availability** - Data survives broker failures
- **In-Sync Replicas (ISR)** - Ensures data consistency
- **Leader election** - Automatic failover

### Cluster Management
- **Node roles** - Controllers vs Brokers
- **Partition distribution** - Load balancing
- **Configuration management** - Multiple properties files

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         KRaft Cluster                    â”‚
â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ Controller   â”‚  (Manages metadata)   â”‚
â”‚  â”‚   Node 1     â”‚                       â”‚
â”‚  â”‚ Port: 9093   â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚         â”‚                                â”‚
â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                          â”‚
â”‚    â”‚         â”‚                          â”‚
â”‚ â”Œâ”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”                    â”‚
â”‚ â”‚Broker â”‚ â”‚Broker â”‚  (Handle data)     â”‚
â”‚ â”‚Node 2 â”‚ â”‚Node 3 â”‚                    â”‚
â”‚ â”‚  9092 â”‚ â”‚  9094 â”‚                    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                          â”‚
â”‚  Topics with replication factor 2       â”‚
â”‚  spread across both brokers             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Common Commands Reference

### Cluster Management
```bash
# Start controller
kafka-server-start.sh config/controller.properties

# Start broker
kafka-server-start.sh config/broker1.properties

# Stop all Kafka processes
pkill -f kafka.Kafka
```

### Topic Operations
```bash
# Create topic
kafka-topics.sh --create --topic my-topic \
  --partitions 3 --replication-factor 2 \
  --bootstrap-server localhost:9092

# List topics
kafka-topics.sh --list --bootstrap-server localhost:9092

# Describe topic
kafka-topics.sh --describe --topic my-topic \
  --bootstrap-server localhost:9092

# Delete topic
kafka-topics.sh --delete --topic my-topic \
  --bootstrap-server localhost:9092
```

### Producer/Consumer
```bash
# Console producer
kafka-console-producer.sh --topic my-topic \
  --bootstrap-server localhost:9092

# Console consumer
kafka-console-consumer.sh --topic my-topic \
  --from-beginning --bootstrap-server localhost:9092

# Consumer group details
kafka-consumer-groups.sh --describe \
  --group my-group --bootstrap-server localhost:9092
```

## Production Best Practices

### Cluster Sizing
- Minimum 3 controllers for production
- Add brokers based on throughput requirements
- Separate controller and broker roles in large clusters

### Replication
- Use replication factor â‰¥ 3 for critical data
- Set min.insync.replicas = 2 for durability
- Monitor ISR health regularly

### Configuration
- Tune `num.partitions` for parallelism
- Configure `log.retention.hours` based on storage
- Set appropriate `socket.buffer` sizes for network

### Monitoring
- Track broker CPU/memory/disk usage
- Monitor under-replicated partitions
- Watch consumer lag
- Use Kafka UI or JMX metrics

## Next Steps

Now that you know Kafka basics, explore:

1. **Kafka Connect** - Integration with external systems
2. **Kafka Streams** - Stream processing applications
3. **Schema Registry** - Manage Avro/JSON schemas
4. **Security** - SSL/SASL authentication, ACLs
5. **Performance Tuning** - Optimize throughput and latency

## Resources

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [KRaft Mode Guide](https://kafka.apache.org/documentation/#kraft)
- [Kafka Operations Guide](https://kafka.apache.org/documentation/#operations)

## Thank You!

Great job completing this workshop! You now have the skills to:
- Install and configure Kafka in KRaft mode
- Manage multi-broker clusters
- Handle topic operations and replication
- Troubleshoot common issues

Happy streaming! ğŸš€
