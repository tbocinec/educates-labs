# Module 1: Introduction to Data Governance

Welcome to the Kafka Schema Registry workshop! In this module, you'll learn why data governance is critical for event-driven systems and how Schema Registry solves common data evolution challenges.

## Why Data Governance Matters

### The Problem: Uncontrolled Data Evolution

Imagine you're running an e-commerce platform with Kafka. Your order processing system works perfectly... until:

âŒ **Developer A** changes the `OrderCreated` event structure  
âŒ **Consumer B** breaks because it expects the old format  
âŒ **Production outage** at 2 AM  
âŒ **Lost revenue** while you debug and redeploy  

This is the reality of **uncontrolled schema evolution**.

### Real-World Horror Stories

**Scenario 1: The Renamed Field**
```json
// Old format (what consumers expect)
{"order_id": "123", "total_price": 99.99}

// New format (what producer sends)
{"order_id": "123", "total_amount": 99.99}  // Renamed!

// Result: Consumers can't find "total_price" â†’ NULL values â†’ broken reports
```

**Scenario 2: The Missing Default**
```json
// Old format
{"order_id": "123", "customer_id": "C001"}

// New format (added required field)
{"order_id": "123", "customer_id": "C001", "payment_method": "CARD"}

// Result: Old messages fail validation â†’ consumers crash
```

**Scenario 3: The Type Change**
```json
// Old: price as number
{"product_id": "P123", "price": 29.99}

// New: price as string
{"product_id": "P123", "price": "29.99"}

// Result: Type mismatch â†’ deserialization errors
```

### The Cost of No Governance

- â° **Debugging time**: Hours to identify schema mismatches
- ğŸ’° **Lost revenue**: Downtime during peak hours
- ğŸ”§ **Emergency fixes**: Rushed patches and rollbacks
- ğŸ˜¤ **Team friction**: Blame games between teams
- ğŸ“‰ **Technical debt**: Workarounds accumulate

## The Solution: Schema Registry

Schema Registry is a **centralized schema management service** that:

âœ… **Enforces contracts** between producers and consumers  
âœ… **Validates schema evolution** before deployment  
âœ… **Prevents breaking changes** from reaching production  
âœ… **Enables independent evolution** of services  
âœ… **Provides schema versioning** and history  

### How Schema Registry Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Producer   â”‚                    â”‚ Schema Registry  â”‚
â”‚             â”‚  1. Register       â”‚                  â”‚
â”‚             â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  - Stores schemasâ”‚
â”‚             â”‚     schema         â”‚  - Assigns IDs   â”‚
â”‚             â”‚                    â”‚  - Validates     â”‚
â”‚             â”‚  2. Get ID         â”‚                  â”‚
â”‚             â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”‚ 3. Send message with schema ID
      â”‚
      v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka     â”‚     [magic byte][schema ID][data]
â”‚   Topic     â”‚     [   0x00   ][    1    ][{...}]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”‚ 4. Read message
      â”‚
      v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Consumer   â”‚  5. Fetch schema   â”‚ Schema Registry  â”‚
â”‚             â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                  â”‚
â”‚             â”‚     by ID          â”‚  (cached!)       â”‚
â”‚             â”‚                    â”‚                  â”‚
â”‚             â”‚  6. Deserialize    â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     with schema    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Concepts

#### 1. **Schema**
A formal definition of your data structure (Avro, JSON Schema, or Protobuf)

```json
{
  "type": "record",
  "name": "OrderCreated",
  "fields": [
    {"name": "order_id", "type": "string"},
    {"name": "total_price", "type": "double"}
  ]
}
```

#### 2. **Subject**
A named context for schema evolution (usually `{topic}-value` or `{topic}-key`)

Example: `orders-value` â†’ schemas for values in the `orders` topic

#### 3. **Schema ID**
A globally unique integer assigned to each schema version

- Schema ID `1` â†’ `OrderCreated` v1
- Schema ID `2` â†’ `OrderCreated` v2 (with new optional fields)

#### 4. **Wire Format**
How messages are stored in Kafka:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Magic Byteâ”‚ Schema ID  â”‚ Avro Binary Data â”‚
â”‚  (0x00)   â”‚  (4 bytes) â”‚  (variable)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The magic byte (`0x00`) indicates: "This message uses Schema Registry"

#### 5. **Compatibility Mode**
Rules that determine what schema changes are allowed:

- **BACKWARD**: New schema can read old data (most common)
- **FORWARD**: Old schema can read new data
- **FULL**: Both backward and forward compatible
- **NONE**: No compatibility checks (dangerous!)

## Understanding Wire Format

Let's examine a real Kafka message with Schema Registry:

```
Hexadecimal representation:
00 00 01 06 4F 52 44 2D 31 32 33 ...
â”‚   â”‚           â”‚
â”‚   â”‚           â””â”€ Avro binary data starts here
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Schema ID = 1 (4bytes)
â”‚  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Magic byte ( 1byte)
```

**Without Schema Registry** (plain JSON):
```
Size: ~150 bytes per message
{"order_id":"ORD-123","customer_id":"CUST-001","total_price":99.99,...}
```

**With Schema Registry** (Avro):
```
Size: ~40 bytes per message (60% smaller!)
[0x00][0x00 0x00 0x00 0x01][binary data]
```

### Benefits of Wire Format

âœ… **Compact**: Binary encoding reduces message size  
âœ… **Fast**: No JSON parsing overhead  
âœ… **Schema enforcement**: Invalid data rejected at serialization  
âœ… **Evolution support**: Schema ID links to versioning  

## Hands-On: Explore Your Environment

Let's check if Schema Registry is ready:

```terminal:execute
command: curl http://localhost:8081/subjects
session: 1
```

Expected output: `[]` (empty list - no schemas yet)

If you see an error, ensure Docker Compose is running:

```terminal:execute
command: docker compose up -d
session: 1
```

```terminal:execute
command: docker ps
session: 1
```

You should see three containers:
- `kafka` (port 9092)
- `schema-registry` (port 8081)
- `kafka-ui` (port 8080)

## What's Next?

In the next module, you'll:

1. âœ… Create your first Avro schema
2. âœ… Register it with Schema Registry
3. âœ… Produce messages with schema validation
4. âœ… Inspect the wire format

**Key Takeaway**: Schema Registry transforms Kafka from a "message bus" into a "type-safe event streaming platform" with governance built in.

---

**Time:** 15 minutes  
**Next Module:** [Register and Produce with Schemas](02-register-and-produce.md)

